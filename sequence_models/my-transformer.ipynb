{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import wandb\n",
    "from torchtext.data import RawField, ReversibleField, LabelField\n",
    "from torchtext.datasets import WikiText2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'embedding_dim': 8,\n",
    "            'attention_heads': 4,\n",
    "            'device': 'cuda',\n",
    "            'datafile': './city_names.txt',\n",
    "            'learning_rate': 0.1,\n",
    "            'encoder_blocks': 2,\n",
    "            'decoder_blocks': 2,\n",
    "            'max_tokens': 50,\n",
    "    \n",
    "            #'dropout': 0.1,\n",
    "            #'batch_size': 400,\n",
    "            #'dataset': 'imagenette2-320',\n",
    "            #'init_gain': 5,\n",
    "            #'initializer': None,\n",
    "            #'load_workers': os.cpu_count(), \n",
    "            #'max_epochs': 1000,\n",
    "            #'optimizer': 'SGD',\n",
    "            #'random_seed': 1,\n",
    "            #'training_loops': 4,\n",
    "            #'cuda_device_ids': [0, 1, 2],\n",
    "            #'num_hidden_nodes': 300,\n",
    "         }\n",
    "\n",
    "device = torch.device(config['device'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling list if cities from: https://www.britannica.com/topic/list-of-cities-and-towns-in-the-United-States-2023068\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim=config['embedding_dim'], attention_heads=config['attention_heads']):\n",
    "        super().__init__()\n",
    "        #print('')\n",
    "        k_d = int(embedding_dim / attention_heads)\n",
    "        self.Wq = torch.randn((attention_heads, embedding_dim, k_d))\n",
    "        self.Wk = torch.randn((attention_heads, embedding_dim, k_d))\n",
    "        self.Wv = torch.randn((attention_heads, embedding_dim, k_d))\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    def forward(self, in_vectors):\n",
    "        # in_vectors.shape = (max_tokens, embedding_dim)\n",
    "        #print('in_vectors.shape:', in_vectors.shape)\n",
    "        #print('self.Wq.shape:', self.Wq.shape)\n",
    "        #print('self.Wk.shape:', self.Wk.shape)\n",
    "        #print('self.Wv.shape:', self.Wv.shape)\n",
    "        \n",
    "        queries = torch.matmul(in_vectors, self.Wq) #shape = (heads, max_tokens, k_d)\n",
    "        keys = torch.matmul(in_vectors, self.Wk) #shape = (heads, max_tokens, k_d)\n",
    "        values = torch.matmul(in_vectors, self.Wv) #shape = (heads, max_tokens, k_d)\n",
    "        k_d = keys.shape[2]\n",
    "\n",
    "        scores = torch.matmul(queries, torch.transpose(keys, 1,2)) #shape = (heads, max_tokens, num vectors)\n",
    "        #print('scores:', scores)\n",
    "        #print('scores / math.sqrt(k_d):', scores / math.sqrt(k_d))\n",
    "        normalized_scores = self.softmax(scores / math.sqrt(k_d)) #shape = (heads, max_tokens, num vectors)\n",
    "        Zi = torch.matmul(normalized_scores, values)  #shape = (heads, max_tokens, k_d)\n",
    "        Z = torch.squeeze(torch.cat(torch.split(Zi, 1, dim=0), 2)) #shape = (max_tokens, embedding_dim)\n",
    "\n",
    "        return Z  # shape = (max_tokens, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim=config['embedding_dim'], attention_heads=config['attention_heads']):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = SelfAttention(embedding_dim=embedding_dim, attention_heads=attention_heads)\n",
    "        self.attn_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.ffnn = torch.nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.ffnn_norm = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, in_vectors):\n",
    "        # in_vectors.shape = (max_tokens, embedding_dim)\n",
    "        #print('in_vectors:', in_vectors)\n",
    "        attn = self.attention(in_vectors)\n",
    "        #print('attn:', attn)\n",
    "        a1 = self.attn_norm(in_vectors + attn)  # shape = (max_tokens, embedding_dim)\n",
    "        a2 = self.ffnn_norm(a1 + self.ffnn(a1))  # shape = (max_tokens, embedding_dim)\n",
    "        return a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim=config['embedding_dim'], \n",
    "                 attention_heads=config['attention_heads'], \n",
    "                 num_blocks=config['encoder_blocks']):\n",
    "        super().__init__()\n",
    "                \n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            blocks.append(EncoderBlock(embedding_dim=embedding_dim, attention_heads=attention_heads))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward(self, in_vectors):\n",
    "        # FIXME: positional offsets\n",
    "        return self.blocks(in_vectors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim=config['embedding_dim'], attention_heads=config['attention_heads']):\n",
    "        super().__init__()\n",
    "        k_d = int(embedding_dim / attention_heads)\n",
    "        self.Wq = torch.randn((attention_heads, embedding_dim, k_d))\n",
    "        self.Wk = torch.randn((attention_heads, embedding_dim, k_d))\n",
    "        self.Wv = torch.randn((attention_heads, embedding_dim, k_d))\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    def forward(self, in_vectors, encoder_vectors):\n",
    "        # in_vectors.shape = (number of vectors, embedding_dimension)\n",
    "        queries = torch.matmul(in_vectors, self.Wq) #shape = (heads, num vectors, k_d)\n",
    "        keys = torch.matmul(encoder_vectors, self.Wk) #shape = (heads, num vectors, k_d)\n",
    "        values = torch.matmul(encoder_vectors, self.Wv) #shape = (heads, num vectors, k_d)\n",
    "        k_d = keys.shape[2]\n",
    "\n",
    "        scores = torch.matmul(queries, torch.transpose(keys, 1,2)) #shape = (heads, num vectors, num vectors)\n",
    "        #print('scores:', scores)\n",
    "        #print('scores / math.sqrt(k_d):', scores / math.sqrt(k_d))\n",
    "        normalized_scores = self.softmax(scores / math.sqrt(k_d)) #shape = (heads, num vectors, num vectors)\n",
    "        Zi = torch.matmul(normalized_scores, values)  #shape = (heads, num vectors, k_d)\n",
    "        Z = torch.squeeze(torch.cat(torch.split(Zi, 1, dim=0), 2)) #shape = (num vectors, embedding_dim)\n",
    "\n",
    "        return Z  # shape = (num vectors, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim=config['embedding_dim'], attention_heads=config['attention_heads']):\n",
    "        super().__init__()\n",
    "        \n",
    "        # FIXME: mask out future self-attention\n",
    "        self.self_attention = SelfAttention(embedding_dim=embedding_dim, attention_heads=attention_heads)\n",
    "        self.self_attn_norm = nn.LayerNorm(embedding_dim) \n",
    "        self.enc_attention = EncoderDecoderAttention(embedding_dim=embedding_dim, attention_heads=attention_heads)\n",
    "        self.enc_attn_norm = nn.LayerNorm(embedding_dim) \n",
    "        self.ffnn = torch.nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.ffnn_norm = nn.LayerNorm(embedding_dim) \n",
    "\n",
    "    def forward(self, all_vectors):\n",
    "        in_vectors, encoder_vectors = all_vectors\n",
    "        a1 = self.self_attn_norm(in_vectors + self.self_attention(in_vectors))\n",
    "        a2 = self.enc_attn_norm(a1 + self.enc_attention(a1, encoder_vectors))\n",
    "        a3 = self.ffnn_norm(a2 + self.ffnn(a1))\n",
    "        print('a3[:,0]=', a3[:,0])\n",
    "        return (a3, encoder_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim=config['embedding_dim'], \n",
    "                 attention_heads=config['attention_heads'], \n",
    "                 num_blocks=config['decoder_blocks']):\n",
    "        super().__init__()\n",
    "                \n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            blocks.append(DecoderBlock(embedding_dim=embedding_dim, attention_heads=attention_heads))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_vectors):\n",
    "        out_vectors, _ = self.blocks((encoder_vectors, encoder_vectors))\n",
    "        return out_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab, \n",
    "                 embedding_dim=config['embedding_dim'], \n",
    "                 attention_heads=config['attention_heads'], \n",
    "                 encoder_blocks=config['encoder_blocks'],\n",
    "                 decoder_blocks=config['decoder_blocks']):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.encode = Encoder(embedding_dim=embedding_dim, attention_heads=attention_heads, num_blocks=encoder_blocks)\n",
    "        self.decode = Decoder(embedding_dim=embedding_dim, attention_heads=attention_heads, num_blocks=decoder_blocks)\n",
    "\n",
    "        self.ffnn = nn.Linear(embedding_dim, len(self.vocab))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, string):\n",
    "        embedded = self.vocab(string)\n",
    "        print('embedded.shape:', embedded.shape)\n",
    "        encoded = self.encode(embedded)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded\n",
    "        return self.softmax(self.ffnn(decoded)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(nn.Module):\n",
    "    def __init__(self, \n",
    "                 data_file=config['datafile'], \n",
    "                 embedding_dim=config['embedding_dim'], \n",
    "                 split_field='', \n",
    "                 max_tokens=config['max_tokens'],\n",
    "                 device=device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_file = data_file\n",
    "        self.split_field = split_field\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "        self.itos = []\n",
    "        self.stoi = {}\n",
    "        self.stoe = {}\n",
    "        self.freq = defaultdict(int)\n",
    "        self._register_token('<EOS>')\n",
    "        self._register_token(None)\n",
    "\n",
    "        self.load_strings(self.data_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def _register_token(self, token):\n",
    "        if not token in self.stoi:\n",
    "            self.itos.append(token)\n",
    "            self.stoi[token] = len(self) - 1\n",
    "            self.stoe[token] = torch.randn(self.embedding_dim)\n",
    "        self.freq[token] += 1\n",
    "\n",
    "    def tokenize(self, string):\n",
    "        if self.split_field == '':\n",
    "            ret = list(string)\n",
    "        else:\n",
    "            ret = string.split(self.split_field)\n",
    "        return list(map(str.lower, ret))\n",
    "\n",
    "    def load_strings(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                for token in self.tokenize(line):\n",
    "                    self._register_token(token)\n",
    "                    \n",
    "    def embed(self, string):\n",
    "        tokens = self.tokenize(string)\n",
    "        tokens = tokens[:self.max_tokens - 1] + ['<EOS>']\n",
    "        if len(tokens) < self.max_tokens:\n",
    "            tokens.extend([None] * (self.max_tokens - len(tokens)))\n",
    "        vectors = [self.stoe[token] for token in tokens]\n",
    "        tensors = list(map(lambda t: t.unsqueeze(0), vectors))\n",
    "        return torch.cat(tensors, 0)\n",
    "                    \n",
    "    def forward(self, string):\n",
    "        return self.embed(string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab()\n",
    "model = Transformer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=eval_model('New York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=Vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
