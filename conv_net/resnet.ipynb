{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alethea's Attempt at ResNet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=\"my-resnet34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_dev = \"cuda\"\n",
    "device = torch.device(cuda_dev if use_cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "#if use_cuda:\n",
    "#    print('-', torch.cuda.get_device_name(cuda_dev_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init(config=args)\n",
    "wandb.config.initial_lr = 0.1\n",
    "wandb.config.load_workers = 20\n",
    "wandb.config.batch_size = 700\n",
    "wandb.config.max_epochs = 150\n",
    "wandb.config.training_loops = 1\n",
    "wandb.config.dropout=.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data. \n",
    "\n",
    "I'm using advice from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ about regularizing image data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256),        \n",
    "                                transforms.CenterCrop(224),    \n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "\n",
    "#datadir = \"/home/apower/data/oxford-iiit-pet\"\n",
    "datadir = \"/mnt/data/oxford-iiit-pet\"\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "devdir = os.path.join(datadir, 'dev')\n",
    "testdir = os.path.join(datadir, 'test')\n",
    "\n",
    "X_train = torchvision.datasets.ImageFolder(traindir, transform)\n",
    "X_dev = torchvision.datasets.ImageFolder(devdir, transform)\n",
    "X_test = torchvision.datasets.ImageFolder(testdir, transform)\n",
    "\n",
    "num_labels = len(X_train.classes)\n",
    "\n",
    "print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\ntest_set:', len(X_test), '\\nlabels:', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=wandb.config.batch_size, shuffle=True, num_workers=wandb.config.load_workers)\n",
    "dev_loader = DataLoader(X_dev, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basing this on the resnet diagram from: https://cv-tricks.com/keras/understand-implement-resnets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "                \n",
    "        if in_channels == out_channels:\n",
    "            self.proj = None \n",
    "        else:\n",
    "            self.proj = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.proj:\n",
    "            return self.proj(X)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if in_channels == out_channels:\n",
    "            stride = 1\n",
    "        else:\n",
    "            stride = 2\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride),\n",
    "                                    torch.nn.BatchNorm2d(out_channels), \n",
    "                                    nn.Dropout2d(p=wandb.config.dropout),\n",
    "                                    nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                                    torch.nn.BatchNorm2d(out_channels), \n",
    "                                    nn.Dropout2d(p=wandb.config.dropout),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        self.proj = Projection(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        #prefix = ' ' * 2\n",
    "        #print(prefix, 'START ResidualBlock')\n",
    "        #print(prefix, 'in_channels:', self.in_channels)\n",
    "        #print(prefix, 'out_channels:', self.in_channels)\n",
    "        #print(prefix, 'stride_channels:', self.in_channels)\n",
    "        #print(prefix, 'layer1:', self.layer1)\n",
    "        #print(prefix, 'layer2:', self.layer2)\n",
    "        a = X\n",
    "        #print(prefix, 'Initial Shape', a.size())\n",
    "        a = self.layer1(a)\n",
    "        #print(prefix, 'After Conv 1:', a.size())\n",
    "        a = self.layer2(a)\n",
    "        #print(prefix, 'After Conv 2:', a.size())\n",
    "        #print(prefix, 'END ResidualBlock')\n",
    "        return a + self.proj(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self. num_labels = num_labels\n",
    "        \n",
    "        # 7x7 Conv\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2),\n",
    "                                    nn.BatchNorm2d(num_features=64),\n",
    "                                    nn.Dropout2d(p=wandb.config.dropout),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # 3x3 MaxPool\n",
    "        self.layer2 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                    nn.BatchNorm2d(num_features=64),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # Stage 1\n",
    "        self.stage1 = nn.Sequential(ResidualBlock(in_channels=64, out_channels=64),\n",
    "                                    ResidualBlock(in_channels=64, out_channels=64),\n",
    "                                    ResidualBlock(in_channels=64, out_channels=64))\n",
    "\n",
    "        # Stage 2\n",
    "        self.stage2 = nn.Sequential(ResidualBlock(in_channels=64, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128))\n",
    "\n",
    "        # Stage 3\n",
    "        self.stage3 = nn.Sequential(ResidualBlock(in_channels=128, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256))\n",
    "        \n",
    "        # Stage 4\n",
    "        self.stage4 = nn.Sequential(ResidualBlock(in_channels=256, out_channels=512),\n",
    "                                    ResidualBlock(in_channels=512, out_channels=512),\n",
    "                                    ResidualBlock(in_channels=512, out_channels=512))\n",
    "        \n",
    "\n",
    "        # AveragePool\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=4608, out_features=num_labels),\n",
    "                                nn.Softmax(dim=1)) \n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        prefix = ' ' * 0\n",
    "        a = X\n",
    "        #print(prefix, 'START ResNet34')\n",
    "        #print(prefix, 'Initial Shape', a.size())\n",
    "        \n",
    "        a = self.layer1(X)\n",
    "        #print(prefix, 'After Layer 1:', a.size())\n",
    "        \n",
    "        a = self.layer2(a)\n",
    "        #print(prefix, 'After Layer 2:', a.size())\n",
    "        \n",
    "        a = self.stage1(a)\n",
    "        #print(prefix, 'After Stage 1:', a.size())\n",
    "        \n",
    "        a = self.stage2(a)\n",
    "        #print(prefix, 'After Stage 2:', a.size())\n",
    "        \n",
    "        a = self.stage3(a)\n",
    "        #print(prefix, 'After Stage 3:', a.size())\n",
    "        \n",
    "        a = self.stage4(a)\n",
    "        #print(prefix, 'After Stage 4:', a.size())\n",
    "        \n",
    "        a = self.avgpool(a)\n",
    "        #print(prefix, 'After AvgPool:', a.size())\n",
    "        \n",
    "        a = a.reshape(a.size(0), -1)\n",
    "        #print(prefix, 'After Reshape:', a.size())\n",
    "        \n",
    "        a = self.fc(a)\n",
    "        #print(prefix, 'After FC:', a.size())\n",
    "        \n",
    "        #print(prefix, 'END ResNet34')\n",
    "        return a\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34(num_labels=num_labels)\n",
    "\n",
    "# Let's see if we have soemthing saved already\n",
    "#try:\n",
    "#    model = torch.load('resnet.pt')\n",
    "#except:\n",
    "#    pass\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "if use_cuda:\n",
    "    model = model.to(device)\n",
    "\n",
    "# Magic\n",
    "#wandb.watch(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_batch, local_labels = iter(train_loader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = local_batch.to(device), local_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = criterion(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, learning_rate=0.1, losses=[10**10], max_epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    wandb.config.optimizer = \"SGD\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        batch = 0\n",
    "        t0 = time.time()\n",
    "        for local_batch, local_labels in loader:\n",
    "            # Transfer to GPU\n",
    "            X, y = local_batch.to(device), local_labels.to(device)\n",
    "            y_pred = model.forward(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('epoch:', epoch, 'batch:', batch, 'loss:', loss.item())\n",
    "            batch += 1\n",
    "        t1 = time.time()\n",
    "        duration = t1-t0\n",
    "        wandb.log({'epoch': epoch, 'loss': loss.item(), 'secs_per_epoch': duration})\n",
    "        print(' ' * 4, '%.1f seconds -' % (duration), 'epoch:', epoch, 'loss:', loss.item())\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [10**10]\n",
    "learning_rate = wandb.config.initial_lr\n",
    "max_epochs = wandb.config.max_epochs\n",
    "total_loops = wandb.config.training_loops\n",
    "model.train()\n",
    "for i in range(total_loops):\n",
    "    # train model\n",
    "    print('learning_rate:', learning_rate, 'max_epochs:', max_epochs)\n",
    "    model, losses = train_model(model, train_loader, learning_rate, losses, max_epochs)\n",
    "\n",
    "    # save weights\n",
    "    cpu_model = model.to(torch.device('cpu'))\n",
    "    torch.save(cpu_model, 'resnet.pt')\n",
    "    if use_cuda:\n",
    "        model = model.to(device)\n",
    "\n",
    "    # slow down learning\n",
    "    learning_rate = learning_rate / 10\n",
    "    #max_epochs = max_epochs + 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the network on the %s images: %.1f %%' % (name, accuracy))\n",
    "    wandb.log({name + '_set_accuracy': accuracy})\n",
    "\n",
    "eval(model, train_loader, 'train')\n",
    "eval(model, dev_loader, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
