{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alethea's Attempt at ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "# Shamelessly stolen from: https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basing this on the resnet diagram from: https://cv-tricks.com/keras/understand-implement-resnets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    \"\"\"Implements a single Convolution layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                 padding_mode='zeros'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "                              stride, padding, dilation, groups, \n",
    "                              bias, padding_mode)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) # Do I need to add a ReLU in here? Maybe: ReLU().forward(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.0433, -0.0336,  0.0493],\n",
      "          [ 0.0224,  0.1019,  0.1001],\n",
      "          [-0.0408, -0.1168, -0.0113]],\n",
      "\n",
      "         [[ 0.0136,  0.0998, -0.0105],\n",
      "          [ 0.0400, -0.0456,  0.0639],\n",
      "          [ 0.0699, -0.0696,  0.1902]],\n",
      "\n",
      "         [[ 0.0832, -0.1746, -0.1907],\n",
      "          [-0.1049,  0.0691, -0.1871],\n",
      "          [-0.0276,  0.1535,  0.1923]]],\n",
      "\n",
      "\n",
      "        [[[-0.1066, -0.0549,  0.0300],\n",
      "          [ 0.0261, -0.1431,  0.0460],\n",
      "          [ 0.0217, -0.0153,  0.1679]],\n",
      "\n",
      "         [[-0.0623, -0.1219, -0.0839],\n",
      "          [-0.0378,  0.0910,  0.0437],\n",
      "          [-0.1247,  0.1253,  0.1326]],\n",
      "\n",
      "         [[-0.1290, -0.0888, -0.0208],\n",
      "          [ 0.1539, -0.1096, -0.0183],\n",
      "          [ 0.0043,  0.0917, -0.0418]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1515,  0.0251,  0.1516],\n",
      "          [ 0.1792,  0.1006,  0.1411],\n",
      "          [ 0.0843,  0.1919, -0.1548]],\n",
      "\n",
      "         [[ 0.0478,  0.1888,  0.0375],\n",
      "          [ 0.1686, -0.0645, -0.0321],\n",
      "          [-0.0037, -0.1907,  0.1757]],\n",
      "\n",
      "         [[-0.1782, -0.0062,  0.0317],\n",
      "          [ 0.0691,  0.1223, -0.0413],\n",
      "          [-0.0169, -0.0706,  0.1864]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1619,  0.0391,  0.0457], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmpmodel = ConvModule(in_channels=3, out_channels=3, kernel_size=3)\n",
    "print(list(tmpmodel.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolModule(nn.Module):\n",
    "    \"\"\"Implements a single Max Pool layer\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride=None, padding=0, dilation=1, \n",
    "                 return_indices=False, ceil_mode=False):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size, stride, padding, dilation, \n",
    "                                    return_indices, ceil_mode)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPoolModule(nn.Module):\n",
    "    \"\"\"Implements a single Average Pool layer\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size, stride=None, padding=0, ceil_mode=False, \n",
    "                 count_include_pad=True, divisor_override=None):\n",
    "        super().__init__()\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size, stride, padding, ceil_mode, \n",
    "                                    count_include_pad, divisor_override)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.avgpool(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModule(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0288,  0.0595,  0.0290,  ..., -0.0109, -0.0751,  0.0465],\n",
      "        [ 0.0518, -0.0331,  0.0077,  ...,  0.0485, -0.0016, -0.0042],\n",
      "        [ 0.0934,  0.0565,  0.0011,  ..., -0.0836,  0.0887, -0.0487],\n",
      "        ...,\n",
      "        [ 0.0779, -0.0140,  0.0451,  ...,  0.0603,  0.0381,  0.0747],\n",
      "        [ 0.0624,  0.0643,  0.0161,  ...,  0.0558,  0.0779,  0.0800],\n",
      "        [-0.0760,  0.0754, -0.0955,  ...,  0.0783, -0.0525, -0.0843]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 8.3013e-02, -8.4906e-02,  8.5836e-03,  7.4810e-02,  5.9445e-02,\n",
      "         8.5487e-02, -7.7168e-02, -6.9145e-02, -5.3128e-02, -6.6627e-03,\n",
      "        -7.6876e-02,  3.7216e-02, -6.5353e-02, -1.4852e-02,  3.0931e-02,\n",
      "        -2.5520e-02,  7.2159e-02,  3.7897e-02,  9.0557e-02,  4.6501e-02,\n",
      "         2.1900e-02,  3.0614e-02,  3.2165e-02, -4.0792e-02,  8.3559e-03,\n",
      "        -6.6088e-02, -4.7993e-02, -6.6386e-02,  4.1887e-02, -4.2243e-02,\n",
      "        -3.8193e-02,  8.1635e-02, -5.3732e-03, -9.7534e-02,  2.1129e-02,\n",
      "        -2.3341e-03,  2.1382e-02, -1.0540e-02, -3.7973e-02,  5.7694e-02,\n",
      "        -5.1671e-02, -7.2412e-02,  7.8652e-02, -4.0499e-02,  7.2760e-02,\n",
      "        -3.5022e-02,  2.6669e-02, -3.9007e-02, -9.2620e-02, -2.7347e-03,\n",
      "        -3.9703e-02,  5.8302e-02,  2.5190e-05, -8.5309e-02,  4.1185e-03,\n",
      "         8.1750e-02,  5.4282e-02, -5.7341e-02,  1.8124e-02, -8.4609e-02,\n",
      "        -4.4566e-03,  3.6319e-02,  4.7275e-03, -3.5587e-02,  2.1488e-02,\n",
      "        -8.0968e-02,  2.2020e-02,  1.7966e-02, -8.3624e-02,  9.4818e-02,\n",
      "        -4.7155e-02, -1.6791e-03, -6.2708e-02, -8.0113e-02, -7.5295e-02,\n",
      "         2.2876e-03, -7.1405e-02,  6.9195e-02,  2.9292e-02,  6.0015e-02,\n",
      "         7.8415e-02, -4.0779e-02, -5.1979e-03, -1.6185e-02,  6.7710e-02,\n",
      "         8.7023e-02, -3.6371e-02, -5.0459e-02,  5.1701e-02, -6.8380e-02,\n",
      "         7.0282e-02,  1.1375e-02,  8.3957e-02, -2.2182e-02, -7.4738e-02,\n",
      "        -8.8707e-02,  1.9563e-02,  9.4399e-02,  8.0898e-02, -5.1972e-02],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmpmodel = LinearModule(in_features=100, out_features=100)\n",
    "print(list(tmpmodel.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxModule(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualModule(nn.Module):\n",
    "    \"\"\"Implements a single residual block from a given stage\"\"\"\n",
    "    \n",
    "    def __init__(self, stage_num):\n",
    "        super().__init__()\n",
    "\n",
    "        # p = parameters\n",
    "        p = {1: {'in_channels': [64, 64, 64], \n",
    "                 'out_channels': [64, 64, 256], \n",
    "                 'kernel_size': [1, 3, 1],\n",
    "                 'stride': [1] * 3, \n",
    "                 'padding': [1, 0, 0], \n",
    "                 'dilation': [1] * 3, \n",
    "                 'groups': [1] * 3, \n",
    "                 'bias': [True] * 3,\n",
    "                 'padding_mode': ['zeros'] * 3 },\n",
    "             2: {'in_channels': [128, 128, 128], \n",
    "                 'out_channels': [128, 128, 512], \n",
    "                 'kernel_size': [1, 3, 1],\n",
    "                 'stride': [1] * 3, \n",
    "                 'padding': [1, 0, 0],\n",
    "                 'dilation': [1] * 3, \n",
    "                 'groups': [1] * 3, \n",
    "                 'bias': [True] * 3,\n",
    "                 'padding_mode': ['zeros'] * 3 },\n",
    "             3: {'in_channels': [256,256, 256], \n",
    "                 'out_channels': [256, 256, 1024], \n",
    "                 'kernel_size': [1, 3, 1],\n",
    "                 'stride': [1] * 3, \n",
    "                 'padding': [1, 0, 0], \n",
    "                 'dilation': [1] * 3, \n",
    "                 'groups': [1] * 3, \n",
    "                 'bias': [True] * 3,\n",
    "                 'padding_mode': ['zeros'] * 3 },\n",
    "             4: {'in_channels': [512, 512, 512], \n",
    "                 'out_channels': [512, 512, 2048], \n",
    "                 'kernel_size': [1, 3, 1],\n",
    "                 'stride': [1] * 3, \n",
    "                 'padding': [1, 0, 0], \n",
    "                 'dilation': [1] * 3, \n",
    "                 'groups': [1] * 3, \n",
    "                 'bias': [True] * 3,\n",
    "                 'padding_mode': ['zeros'] * 3 },\n",
    "            }[stage_num]\n",
    "        \n",
    "        # Pytorch doesn't seem to be able to find trainable parameters if we put submodules \n",
    "        # into an array\n",
    "        #\n",
    "        # for i in range(3):\n",
    "        #     self.layers.append()\n",
    "\n",
    "        ReLU(F + x)\n",
    "        i = 0\n",
    "        self.layer0 = ConvModule(p['in_channels'][i], p['out_channels'][i], p['kernel_size'][i], \n",
    "                                 p['stride'][i], p['padding'][i], p['dilation'][i], \n",
    "                                 p['groups'][i], p['bias'][i], p['padding_mode'][i])\n",
    "        i = 1\n",
    "        self.layer1 = ConvModule(p['in_channels'][i], p['out_channels'][i], p['kernel_size'][i], \n",
    "                                 p['stride'][i], p['padding'][i], p['dilation'][i], \n",
    "                                 p['groups'][i], p['bias'][i], p['padding_mode'][i])\n",
    "        i = 2\n",
    "        self.layer2 = ConvModule(p['in_channels'][i], p['out_channels'][i], p['kernel_size'][i], \n",
    "                                 p['stride'][i], p['padding'][i], p['dilation'][i], \n",
    "                                 p['groups'][i], p['bias'][i], p['padding_mode'][i])\n",
    "        \n",
    "                    \n",
    "    def forward(self, x):\n",
    "        a = x\n",
    "        a = self.layer0.forward(a)\n",
    "        a = self.layer1.forward(a)\n",
    "        a = self.layer2.forward(a) \n",
    "        return a + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage(nn.Module):\n",
    "    \"\"\"Implements each of the four stages of residual blocks. \n",
    "    One instance of this class is one stage\"\"\"\n",
    "    \n",
    "    def __init__(self, stage_num):\n",
    "        super().__init__()\n",
    "    \n",
    "        \n",
    "        # Pytorch doesn't seem to be able to find trainable parameters if we put submodules \n",
    "        # into an array\n",
    "        #\n",
    "        # self.stage_num = stage_num\n",
    "        #\n",
    "        # self.num_blocks = {1: 3, \n",
    "        #                    2: 3, \n",
    "        #                    3: 6, \n",
    "        #                    4: 3}[stage_num]\n",
    "        #\n",
    "        # self.blocks = []\n",
    "        # for i in range(self.num_blocks):\n",
    "        #     self.blocks.append(ResidualModule(stage_num))\n",
    "\n",
    "        self.block0 = ResidualModule(stage_num)\n",
    "        self.block1 = ResidualModule(stage_num)\n",
    "        self.block2 = ResidualModule(stage_num)\n",
    "        if stage_num == 3:\n",
    "            self.block3 = ResidualModule(stage_num)\n",
    "            self.block4 = ResidualModule(stage_num)\n",
    "            self.block5 = ResidualModule(stage_num)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # a = x\n",
    "        # for block in self.blocks:\n",
    "        #     a = block.forward(x)\n",
    "        # return a\n",
    "        a = x\n",
    "        a = self.block0.forward(a)\n",
    "        a = self.block1.forward(a)\n",
    "        a = self.block2.forward(a)\n",
    "        if stage_num == 3:\n",
    "            a = self.block3.forward(a)\n",
    "            a = self.block4.forward(a)\n",
    "            a = self.block5.forward(a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 7x7 Conv\n",
    "        self.layer1 = ConvModule(in_channels=3, out_channels=64, \n",
    "                                 kernel_size=7, stride=2, padding=4)\n",
    "\n",
    "        # 3x3 MaxPool\n",
    "        self.layer2 = MaxPoolModule(kernel_size=3, stride=2, padding=2)\n",
    "\n",
    "        # Residual Stages\n",
    "        self.stage1 = Stage(1)\n",
    "        self.stage2 = Stage(2)\n",
    "        self.stage3 = Stage(3)\n",
    "        self.stage4 = Stage(4)\n",
    "\n",
    "        # AveragePool\n",
    "        self.avgpool = AvgPoolModule(kernel_size=7)  # FIXME\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.linear = LinearModule(in_features=1000, out_features=num_labels)\n",
    "        \n",
    "        # I think this one is handled by choosing criterion = nn.CrossEntropyLoss() below\n",
    "        # self.softmax = SoftmaxModule(dim=num_labels)  # Is this needed? \n",
    "\n",
    "    def forward(self, x):\n",
    "        a = x\n",
    "        a = self.layer1.forward(a)\n",
    "        a = self.layer2.forward(a)\n",
    "        a = self.stage1.forward(a)\n",
    "        a = self.stage2.forward(a)\n",
    "        a = self.stage3.forward(a)\n",
    "        a = self.stage4.forward(a)\n",
    "        a = self.avgpool.forward(a)\n",
    "        a = self.linear.forward(a)\n",
    "        a = self.softmax.forward(a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data. \n",
    "\n",
    "I'm using advice from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ about regularizing image data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256),        \n",
    "                                transforms.CenterCrop(224),    \n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "\n",
    "datadir = \"/home/apower/data/oxford-iiit-pet\"\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "devdir = os.path.join(datadir, 'dev')\n",
    "testdir = os.path.join(datadir, 'test')\n",
    "\n",
    "X_train = torchvision.datasets.ImageFolder(traindir, transform)\n",
    "X_dev = torchvision.datasets.ImageFolder(devdir, transform)\n",
    "X_test = torchvision.datasets.ImageFolder(testdir, transform)\n",
    "\n",
    "# It's better to pre-divide data into train/dev/test. That way it doesn't randomly shift between runs. \n",
    "\n",
    "#dataset = torchvision.datasets.ImageFolder(datadir, transform)\n",
    "#total_pics = len(dataset)\n",
    "#test_pics = int(min(total_pics * .1, 1000))\n",
    "#dev_pics = int(min(total_pics * .1, 1000))\n",
    "#train_pics = total_pics - (dev_pics + test_pics)\n",
    "#(X_train, X_dev, X_test) = torch.utils.data.random_split(dataset, (train_pics, dev_pics, test_pics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\ntest_set:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pic = torchvision.transforms.ToPILImage()\n",
    "to_pic(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pic(X_dev[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_pic(X_test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Do it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_labels=len(X_train.classes))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo!!!! We have parameters! :-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=1, shuffle=True)\n",
    "dev_loader = DataLoader(X_dev, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=1, shuffle=True)\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "losses = []\n",
    "for epoch in range(max_epochs):\n",
    "    for local_batch, local_labels in train_loader:\n",
    "        # Transfer to GPU\n",
    "        X, y = local_batch.to(device), local_labels.to(device)\n",
    "        y_pred = model.forward(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        losses.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch:', epoch, 'loss:', loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
