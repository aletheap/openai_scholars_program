{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alethea's Attempt at ResNet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GeForce RTX 2080 Ti\n",
      "1 GeForce GTX 1080 Ti\n",
      "2 GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(i, torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/aletheap/my-resnet34-augmenting\" target=\"_blank\">https://app.wandb.ai/aletheap/my-resnet34-augmenting</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/aletheap/my-resnet34-augmenting/runs/yvfo9bdu\" target=\"_blank\">https://app.wandb.ai/aletheap/my-resnet34-augmenting/runs/yvfo9bdu</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/aletheap/my-resnet34-augmenting/runs/yvfo9bdu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "            'device': 'cuda:0',\n",
    "            'initializer': 'xavier_normal_',\n",
    "            'learning_rate': 0.2,\n",
    "            'load_workers': 20, \n",
    "            'batch_size': 190,\n",
    "            'max_epochs': 200,\n",
    "            'training_loops': 1,\n",
    "            'dropout': 0.5,\n",
    "            'optimizer': 'SGD',\n",
    "            'dataset': 'oxford-iiit-pet',\n",
    "            'random_seed': 1,\n",
    "         }\n",
    "wandb.init(project=\"my-resnet34-augmenting\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb.config.random_seed:\n",
    "    torch.manual_seed(wandb.config.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA\n",
    "#use_cuda = torch.cuda.is_available()\n",
    "#cuda_dev = wandb.config.device\n",
    "#device = torch.device(cuda_dev if use_cuda else \"cpu\")\n",
    "device = torch.device(wandb.config.device)\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data. \n",
    "\n",
    "I'm using advice from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ about regularizing image data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datadir: /home/apower/data/oxford-iiit-pet\n",
      "traindir: /home/apower/data/oxford-iiit-pet/train\n",
      "devdir: /home/apower/data/oxford-iiit-pet/dev\n",
      "testdir: /home/apower/data/oxford-iiit-pet/test\n",
      "training_set: 5760 \n",
      "dev_set: 800 \n",
      "test_set: 800 \n",
      "labels: 38\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.RandomCrop(224),\n",
    "                                transforms.ColorJitter(brightness=.5, contrast=.5, saturation=.5, hue=.5),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(90),\n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "dev_test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "\n",
    "datadir = os.path.join(\"/home/apower/data\", wandb.config.dataset) \n",
    "print('datadir:', datadir)\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "print('traindir:', traindir)\n",
    "devdir = os.path.join(datadir, 'dev')\n",
    "print('devdir:', devdir)\n",
    "testdir = os.path.join(datadir, 'test')\n",
    "print('testdir:', testdir)\n",
    "\n",
    "X_train = torchvision.datasets.ImageFolder(traindir, transform)\n",
    "X_dev = torchvision.datasets.ImageFolder(devdir, dev_test_transform)\n",
    "X_test = torchvision.datasets.ImageFolder(testdir, dev_test_transform)\n",
    "\n",
    "num_labels = len(X_train.classes)\n",
    "\n",
    "print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\ntest_set:', len(X_test), '\\nlabels:', num_labels)\n",
    "#print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\nlabels:', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_dev[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=wandb.config.batch_size, shuffle=True, num_workers=wandb.config.load_workers)\n",
    "dev_loader = DataLoader(X_dev, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basing this on the resnet diagram from: https://cv-tricks.com/keras/understand-implement-resnets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "                \n",
    "        if in_channels == out_channels:\n",
    "            self.proj = None \n",
    "        else:\n",
    "            self.proj = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2)\n",
    "            getattr(nn.init, wandb.config.initializer)(self.proj.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.proj:\n",
    "            return self.proj(X)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if in_channels == out_channels:\n",
    "            stride = 1\n",
    "        else:\n",
    "            stride = 2\n",
    "\n",
    "        conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        getattr(nn.init, wandb.config.initializer)(conv1.weight)\n",
    "        \n",
    "        conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        getattr(nn.init, wandb.config.initializer)(conv2.weight)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(conv1,\n",
    "                                    nn.BatchNorm2d(out_channels), \n",
    "                                    nn.Dropout2d(p=wandb.config.dropout),\n",
    "                                    nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(conv2,\n",
    "                                    nn.BatchNorm2d(out_channels), \n",
    "                                    nn.Dropout2d(p=wandb.config.dropout),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        self.proj = Projection(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X\n",
    "        a = self.layer1(a)\n",
    "        a = self.layer2(a)\n",
    "        return a + self.proj(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self. num_labels = num_labels\n",
    "        \n",
    "        # 7x7 Conv\n",
    "        conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2)\n",
    "        getattr(nn.init, wandb.config.initializer)(conv1.weight)\n",
    "        self.layer1 = nn.Sequential(conv1,\n",
    "                                    nn.BatchNorm2d(num_features=64),\n",
    "                                    nn.Dropout2d(p=wandb.config.dropout),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # 3x3 MaxPool\n",
    "        self.layer2 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                    nn.BatchNorm2d(num_features=64),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # Stage 1\n",
    "        self.stage1 = nn.Sequential(ResidualBlock(in_channels=64, out_channels=64),\n",
    "                                    ResidualBlock(in_channels=64, out_channels=64),\n",
    "                                    ResidualBlock(in_channels=64, out_channels=64))\n",
    "\n",
    "        # Stage 2\n",
    "        self.stage2 = nn.Sequential(ResidualBlock(in_channels=64, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128))\n",
    "\n",
    "        # Stage 3\n",
    "        self.stage3 = nn.Sequential(ResidualBlock(in_channels=128, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256))\n",
    "        \n",
    "        # Stage 4\n",
    "        self.stage4 = nn.Sequential(ResidualBlock(in_channels=256, out_channels=512),\n",
    "                                    ResidualBlock(in_channels=512, out_channels=512),\n",
    "                                    ResidualBlock(in_channels=512, out_channels=512))\n",
    "        \n",
    "\n",
    "        # AveragePool\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected\n",
    "        lin = nn.Linear(in_features=4608, out_features=num_labels)\n",
    "        getattr(nn.init, wandb.config.initializer)(lin.weight)        \n",
    "        self.fc = nn.Sequential(lin, nn.Softmax(dim=1)) \n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        prefix = ' ' * 0\n",
    "        a = X       \n",
    "        a = self.layer1(X)\n",
    "        a = self.layer2(a)\n",
    "        a = self.stage1(a)\n",
    "        a = self.stage2(a)\n",
    "        a = self.stage3(a)\n",
    "        a = self.stage4(a)\n",
    "        a = self.avgpool(a)\n",
    "        a = a.reshape(a.size(0), -1)\n",
    "        a = self.fc(a)\n",
    "        return a\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34(num_labels=num_labels)\n",
    "#wandb.watch(model)\n",
    "#model = nn.DataParallel(model, device_ids=[0,1])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0110,  0.0083, -0.0084, -0.0011, -0.0059, -0.0073, -0.0060,  0.0079,\n",
      "         0.0036, -0.0031,  0.0140, -0.0091, -0.0088,  0.0106, -0.0091,  0.0124,\n",
      "        -0.0066, -0.0114,  0.0139, -0.0132, -0.0122,  0.0093,  0.0112, -0.0137,\n",
      "         0.0012, -0.0020, -0.0071,  0.0092, -0.0046, -0.0021, -0.0062, -0.0076,\n",
      "        -0.0075,  0.0025,  0.0096,  0.0037,  0.0142,  0.0055], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = model.parameters()\n",
    "p = list(params)[-1]\n",
    "print(p)\n",
    "#print(p + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader, name):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    #print('Accuracy of the network on the %s images: %.1f %%' % (name, accuracy))\n",
    "    #wandb.log({name + '_set_accuracy': accuracy})\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, learning_rate=0.1, max_epochs=20):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, wandb.config.optimizer)(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        t0 = time.time()\n",
    "        for local_batch, local_labels in loader:\n",
    "            # Transfer to GPU\n",
    "            X, y = local_batch.to(device), local_labels.to(device)\n",
    "            y_pred = model.forward(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.item()  # <-- If you delete this it won't learn\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        t1 = time.time()\n",
    "        duration = t1-t0\n",
    "        loss_num = loss.item()\n",
    "        train_accuracy = accuracy(model, train_loader, 'train')\n",
    "        dev_accuracy = accuracy(model, dev_loader, 'dev')\n",
    "        wandb.log({'loss': loss.item(), 'secs_per_epoch': duration, 'train_accuracy': train_accuracy, 'dev_accuracy': dev_accuracy, 'relative_accuracy': dev_accuracy / train_accuracy})\n",
    "        print(' ' * 4, '%.1f seconds -' % (duration), 'epoch:', epoch, 'loss:', loss_num, 'train:', train_accuracy, 'dev:', dev_accuracy, 'relative_accuracy:', dev_accuracy / train_accuracy)\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [10**10]\n",
    "learning_rate = wandb.config.learning_rate\n",
    "max_epochs = wandb.config.max_epochs\n",
    "total_loops = wandb.config.training_loops\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1\n",
    "total_loops = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0110,  0.0083, -0.0084, -0.0011, -0.0059, -0.0073, -0.0060,  0.0079,\n",
       "         0.0036, -0.0031,  0.0140, -0.0091, -0.0088,  0.0106, -0.0091,  0.0124,\n",
       "        -0.0066, -0.0114,  0.0139, -0.0132, -0.0122,  0.0093,  0.0112, -0.0137,\n",
       "         0.0012, -0.0020, -0.0071,  0.0092, -0.0046, -0.0021, -0.0062, -0.0076,\n",
       "        -0.0075,  0.0025,  0.0096,  0.0037,  0.0142,  0.0055], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.2 max_epochs: 200\n",
      "     20.4 seconds - epoch: 0 loss: 3.6651437282562256 train: 2.6041666666666665 dev: 3.5 relative_accuracy: 1.344\n",
      "     17.6 seconds - epoch: 1 loss: 3.6651437282562256 train: 2.6041666666666665 dev: 3.375 relative_accuracy: 1.296\n",
      "     17.6 seconds - epoch: 2 loss: 3.6651437282562256 train: 2.6041666666666665 dev: 3.375 relative_accuracy: 1.296\n",
      "     17.6 seconds - epoch: 3 loss: 3.5984771251678467 train: 2.6041666666666665 dev: 3.375 relative_accuracy: 1.296\n"
     ]
    }
   ],
   "source": [
    "for i in range(wandb.config.training_loops):\n",
    "    # train model\n",
    "    print('learning_rate:', wandb.config.learning_rate, 'max_epochs:', wandb.config.max_epochs)\n",
    "    model = train_model(model, \n",
    "                        train_loader, \n",
    "                        learning_rate=wandb.config.learning_rate, \n",
    "                        max_epochs=wandb.config.max_epochs)\n",
    "\n",
    "    # save weights\n",
    "    #cpu_model = model.to(torch.device('cpu'))\n",
    "    #torch.save(cpu_model, 'resnet-augmenting.pt')\n",
    "    #model = model.to(device)\n",
    "\n",
    "    # slow down learning\n",
    "    #learning_rate = learning_rate / 10\n",
    "    #max_epochs = max_epochs + 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = list(model.parameters())[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
