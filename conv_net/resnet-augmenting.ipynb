{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alethea's Attempt at ResNet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import os\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            'batch_size': 700,\n",
    "            #'dataset': 'imagenette2-320',\n",
    "            'dataset': 'oxford-iiit-pet',\n",
    "            'dropout': 0.1,\n",
    "            'init_gain': 5,\n",
    "            'initializer': None,\n",
    "            'learning_rate': 0.1,\n",
    "            'load_workers': os.cpu_count(), \n",
    "            'max_epochs': 1000,\n",
    "            'optimizer': 'SGD',\n",
    "            'random_seed': 1,\n",
    "            'training_loops': 4,\n",
    "            'cuda_device_ids': [3, 2, 1, 0],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['random_seed']:\n",
    "    torch.manual_seed(config['random_seed'])\n",
    "    torch.cuda.manual_seed(config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/aletheap/my-resnet34-augmenting\" target=\"_blank\">https://app.wandb.ai/aletheap/my-resnet34-augmenting</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/aletheap/my-resnet34-augmenting/runs/c9yv51lj\" target=\"_blank\">https://app.wandb.ai/aletheap/my-resnet34-augmenting/runs/c9yv51lj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/aletheap/my-resnet34-augmenting/runs/c9yv51lj"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"my-resnet34-augmenting\", config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data. \n",
    "\n",
    "I'm using advice from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ about regularizing image data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nvidia.dali.ops as ops\n",
    "#import nvidia.dali.types as types\n",
    "#\n",
    "#image_dir = \"data/images\"\n",
    "#batch_size = 8\n",
    "#\n",
    "#class SimplePipeline(Pipeline):\n",
    "#    def __init__(self, batch_size, num_threads, device_id):\n",
    "#        super(SimplePipeline, self).__init__(batch_size, num_threads, device_id, seed = 12)\n",
    "#        self.input = ops.FileReader(file_root = image_dir)\n",
    "#        # instead of path to file directory file with pairs image_name image_label_value can be provided\n",
    "#        # self.input = ops.FileReader(file_root = image_dir, file_list = image_dir + '/file_list.txt')\n",
    "#        self.decode = ops.ImageDecoder(device = 'cpu', output_type = types.RGB)\n",
    "#\n",
    "#    def define_graph(self):\n",
    "#        jpegs, labels = self.input()\n",
    "#        images = self.decode(jpegs)\n",
    "#        return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datadir: /home/apower/data/oxford-iiit-pet\n",
      "traindir: /home/apower/data/oxford-iiit-pet/train\n",
      "devdir: /home/apower/data/oxford-iiit-pet/dev\n",
      "training_set: 5760 \n",
      "dev_set: 800 \n",
      "labels: 38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note to self: Try this: https://www.basicml.com/performance/2019/04/16/pytorch-data-augmentation-with-nvidia-dali.html\n",
    "# cause I think cpu image transforms are a bottleneck for me\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.RandomAffine(30, translate=(.2, .2), scale=(.8, 1.2), shear=None, resample=False, fillcolor=0),\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.RandomCrop(224),\n",
    "                                transforms.ColorJitter(brightness=.5, contrast=.5, saturation=.5, hue=.5),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(180),\n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "dev_test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "\n",
    "datadir = os.path.join(\"/home/apower/data\", config['dataset']) \n",
    "print('datadir:', datadir)\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "print('traindir:', traindir)\n",
    "devdir = os.path.join(datadir, 'dev')\n",
    "print('devdir:', devdir)\n",
    "#testdir = os.path.join(datadir, 'test')\n",
    "#print('testdir:', testdir)\n",
    "\n",
    "X_train = torchvision.datasets.ImageFolder(traindir, transform)\n",
    "X_dev = torchvision.datasets.ImageFolder(devdir, dev_test_transform)\n",
    "#X_test = torchvision.datasets.ImageFolder(testdir, dev_test_transform)\n",
    "\n",
    "num_labels = len(X_train.classes)\n",
    "\n",
    "#print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\ntest_set:', len(X_test), '\\nlabels:', num_labels)\n",
    "print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\nlabels:', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_dev[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=config['batch_size'], shuffle=True, num_workers=config['load_workers'])\n",
    "dev_loader = DataLoader(X_dev, batch_size=1, shuffle=False)\n",
    "#test_loader = DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basing this on the resnet diagram from: https://cv-tricks.com/keras/understand-implement-resnets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "                \n",
    "        if in_channels == out_channels:\n",
    "            self.proj = None \n",
    "        else:\n",
    "            self.proj = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2)\n",
    "            if config['initializer']:\n",
    "                getattr(nn.init, config['initializer'])(self.proj.weight, gain=config['init_gain'])\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.proj:\n",
    "            return self.proj(X)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if in_channels == out_channels:\n",
    "            stride = 1\n",
    "        else:\n",
    "            stride = 2\n",
    "\n",
    "        conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        if config['initializer']:\n",
    "            getattr(nn.init, config['initializer'])(conv1.weight, gain=config['init_gain'])\n",
    "        \n",
    "        conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if config['initializer']:\n",
    "            getattr(nn.init, config['initializer'])(conv2.weight, gain=config['init_gain'])\n",
    "        \n",
    "        self.layer1 = nn.Sequential(conv1,\n",
    "                                    nn.BatchNorm2d(out_channels), \n",
    "                                    nn.Dropout2d(p=config['dropout']),\n",
    "                                    nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(conv2,\n",
    "                                    nn.BatchNorm2d(out_channels), \n",
    "                                    nn.Dropout2d(p=config['dropout']),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        self.proj = Projection(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X\n",
    "        a = self.layer1(a)\n",
    "        a = self.layer2(a)\n",
    "        return a + self.proj(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self. num_labels = num_labels\n",
    "        \n",
    "        # 7x7 Conv\n",
    "        conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2)\n",
    "        if config['initializer']:\n",
    "            getattr(nn.init, config['initializer'])(conv1.weight, gain=config['init_gain'])\n",
    "        self.layer1 = nn.Sequential(conv1,\n",
    "                                    nn.BatchNorm2d(num_features=64),\n",
    "                                    nn.Dropout2d(p=config['dropout']),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # 3x3 MaxPool\n",
    "        self.layer2 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                    nn.BatchNorm2d(num_features=64),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "        # Stage 1\n",
    "        self.stage1 = nn.Sequential(ResidualBlock(in_channels=64, out_channels=64),\n",
    "                                    ResidualBlock(in_channels=64, out_channels=64),\n",
    "                                    ResidualBlock(in_channels=64, out_channels=64))\n",
    "\n",
    "        # Stage 2\n",
    "        self.stage2 = nn.Sequential(ResidualBlock(in_channels=64, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128),\n",
    "                                    ResidualBlock(in_channels=128, out_channels=128))\n",
    "\n",
    "        # Stage 3\n",
    "        self.stage3 = nn.Sequential(ResidualBlock(in_channels=128, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256),\n",
    "                                    ResidualBlock(in_channels=256, out_channels=256))\n",
    "        \n",
    "        # Stage 4\n",
    "        self.stage4 = nn.Sequential(ResidualBlock(in_channels=256, out_channels=512),\n",
    "                                    ResidualBlock(in_channels=512, out_channels=512),\n",
    "                                    ResidualBlock(in_channels=512, out_channels=512))\n",
    "        \n",
    "\n",
    "        # AveragePool\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected\n",
    "        lin = nn.Linear(in_features=4608, out_features=num_labels)\n",
    "        if config['initializer']:\n",
    "            getattr(nn.init, config['initializer'])(lin.weight, gain=config['init_gain'])        \n",
    "        self.fc = nn.Sequential(lin, nn.Softmax(dim=1)) \n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        prefix = ' ' * 0\n",
    "        a = X       \n",
    "        a = self.layer1(X)\n",
    "        a = self.layer2(a)\n",
    "        a = self.stage1(a)\n",
    "        a = self.stage2(a)\n",
    "        a = self.stage3(a)\n",
    "        a = self.stage4(a)\n",
    "        a = self.avgpool(a)\n",
    "        a = a.reshape(a.size(0), -1)\n",
    "        a = self.fc(a)\n",
    "        return a\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs:\n",
      "3 : GeForce RTX 2080 Ti\n",
      "2 : GeForce RTX 2080 Ti\n",
      "1 : GeForce RTX 2080 Ti\n",
      "0 : GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:' + str(config['cuda_device_ids'][0]))\n",
    "model = ResNet34(num_labels=num_labels)\n",
    "print(\"Let's use\", len(config['cuda_device_ids']), \"GPUs:\")\n",
    "\n",
    "for i in config['cuda_device_ids']:\n",
    "    print(i, \":\", torch.cuda.get_device_name(i))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=config['cuda_device_ids'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader, name, cpu=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            if not cpu:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_epoch(model, loader, learning_rate, criterion, optimizer):\n",
    "    for local_batch, local_labels in loader:\n",
    "        # Transfer to GPU\n",
    "        X, y = local_batch.to(device), local_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.item()  # <-- If you delete this it won't learn\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return (model, loss.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, learning_rate=0.1, max_epochs=20):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        model, loss = _do_epoch(model, loader, learning_rate, criterion, optimizer)\n",
    "        t1 = time.time()\n",
    "        duration = t1-t0\n",
    "        train_accuracy = accuracy(model, train_loader, 'train')\n",
    "        dev_accuracy = accuracy(model, dev_loader, 'dev')\n",
    "        relative_accuracy = dev_accuracy / train_accuracy\n",
    "        torch.save(model.state_dict(), './resnet-augmenting-' + config['dataset'] + '.pt')\n",
    "        print(' ' * 4, \n",
    "              '%.1f seconds -' % (duration), \n",
    "              'epoch:', epoch, \n",
    "              'lr: %.3f  ' % learning_rate,\n",
    "              'loss: %.3f  ' % loss, \n",
    "              'train: %.3f  ' % train_accuracy, \n",
    "              'dev: %.3f  ' % dev_accuracy, \n",
    "              'relative_accuracy: %.3f  ' % relative_accuracy)\n",
    "        try:\n",
    "            wandb.log({'loss': loss, \n",
    "                   'learning_rate': learning_rate,\n",
    "                   'secs_per_epoch': duration, \n",
    "                   'train_accuracy': train_accuracy, \n",
    "                   'dev_accuracy': dev_accuracy, \n",
    "                   'relative_accuracy': relative_accuracy})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.1 max_epochs: 1000\n",
      "     25.9 seconds - epoch: 0 lr: 0.100   loss: 3.637   train: 2.847   dev: 3.125   relative_accuracy: 1.098  \n",
      "     15.8 seconds - epoch: 1 lr: 0.100   loss: 3.643   train: 2.830   dev: 3.500   relative_accuracy: 1.237  \n"
     ]
    }
   ],
   "source": [
    "learning_rate = config['learning_rate']\n",
    "\n",
    "for i in range(config['training_loops']):\n",
    "    # train model\n",
    "    print('learning_rate:', learning_rate, 'max_epochs:', config['max_epochs'])\n",
    "    model = train_model(model, \n",
    "                        train_loader, \n",
    "                        learning_rate=learning_rate, \n",
    "                        max_epochs=config['max_epochs'])\n",
    "\n",
    "    # slow down learning\n",
    "    learning_rate = learning_rate / 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = config['learning_rate']\n",
    "loader = train_loader\n",
    "max_epochs=config['max_epochs']\n",
    "\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "cProfile.run('_do_epoch(model, loader, learning_rate, criterion, optimizer)', 'resnet.prof')\n",
    "t1=time.time()\n",
    "print(t1-t0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flameprof resnet.prof > resnet_prof.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='resnet_prof.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats('restats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.print_callers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
