{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-34 Official\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GeForce RTX 2080 Ti\n",
      "1 GeForce GTX 1080 Ti\n",
      "2 GeForce GTX 980\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(i, torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_dev = \"cuda:1\"\n",
    "device = torch.device(cuda_dev if use_cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/aletheap/official-resnet34\" target=\"_blank\">https://app.wandb.ai/aletheap/official-resnet34</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/aletheap/official-resnet34/runs/b2m4foty\" target=\"_blank\">https://app.wandb.ai/aletheap/official-resnet34/runs/b2m4foty</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/aletheap/official-resnet34/runs/b2m4foty"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "            'load_workers': 20, \n",
    "            'batch_size': 190,\n",
    "            'max_epochs': 200,\n",
    "            'optimizer': 'SGD',\n",
    "            'dataset': 'oxford-iiit-pet',\n",
    "         }\n",
    "wandb.init(project=\"official-resnet34\", config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data. \n",
    "\n",
    "I'm using advice from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ about regularizing image data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datadir: /home/apower/data/oxford-iiit-pet\n",
      "traindir: /home/apower/data/oxford-iiit-pet/train\n",
      "devdir: /home/apower/data/oxford-iiit-pet/dev\n",
      "testdir: /home/apower/data/oxford-iiit-pet/test\n",
      "training_set: 5760 \n",
      "dev_set: 800 \n",
      "test_set: 800 \n",
      "labels: 38\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.RandomCrop(224),\n",
    "                                transforms.ColorJitter(brightness=.1, contrast=.1, saturation=.1, hue=.1),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(180),\n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "dev_test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "\n",
    "datadir = os.path.join(\"/home/apower/data\", wandb.config.dataset) \n",
    "print('datadir:', datadir)\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "print('traindir:', traindir)\n",
    "devdir = os.path.join(datadir, 'dev')\n",
    "print('devdir:', devdir)\n",
    "testdir = os.path.join(datadir, 'test')\n",
    "print('testdir:', testdir)\n",
    "\n",
    "X_train = torchvision.datasets.ImageFolder(traindir, transform)\n",
    "X_dev = torchvision.datasets.ImageFolder(devdir, dev_test_transform)\n",
    "X_test = torchvision.datasets.ImageFolder(testdir, dev_test_transform)\n",
    "\n",
    "num_labels = len(X_train.classes)\n",
    "\n",
    "print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\ntest_set:', len(X_test), '\\nlabels:', num_labels)\n",
    "#print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\nlabels:', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=wandb.config.batch_size, shuffle=True, num_workers=wandb.config.load_workers)\n",
    "dev_loader = DataLoader(X_dev, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basing this on the resnet diagram from: https://cv-tricks.com/keras/understand-implement-resnets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet34(pretrained=False, progress=True)\n",
    "#wandb.watch(model)\n",
    "#model = nn.DataParallel(model, device_ids=[0,1])\n",
    "if use_cuda:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader, name):\n",
    "    #model = model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    #print('Accuracy of the network on the %s images: %.1f %%' % (name, accuracy))\n",
    "    #wandb.log({name + '_set_accuracy': accuracy})\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, learning_rate=0.1, losses=[10**10], max_epochs=20):\n",
    "    model = model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, wandb.config.optimizer)(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        batch = 0\n",
    "        t0 = time.time()\n",
    "        for local_batch, local_labels in loader:\n",
    "            # Transfer to GPU\n",
    "            X, y = local_batch.to(device), local_labels.to(device)\n",
    "            y_pred = model.forward(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('epoch:', epoch, 'batch:', batch, 'loss:', loss.item())\n",
    "            batch += 1\n",
    "        t1 = time.time()\n",
    "        duration = t1-t0\n",
    "        loss_num = loss.item()\n",
    "        train_accuracy = accuracy(model, train_loader, 'train')\n",
    "        dev_accuracy = accuracy(model, dev_loader, 'dev')\n",
    "        wandb.log({'loss': loss.item(), 'secs_per_epoch': duration, 'train_accuracy': train_accuracy, 'dev_accuracy': dev_accuracy, 'relative_accuracy': dev_accuracy / train_accuracy})\n",
    "        print(' ' * 4, '%.1f seconds -' % (duration), 'epoch:', epoch, 'loss:', loss_num, 'train:', train_accuracy, 'dev:', dev_accuracy, 'relative_accuracy:', dev_accuracy / train_accuracy)\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epochs: 200\n",
      "     25.9 seconds - epoch: 0 loss: 4.078146457672119 train: 2.4652777777777777 dev: 3.75 relative_accuracy: 1.5211267605633803\n",
      "     27.5 seconds - epoch: 1 loss: 4.193048000335693 train: 4.670138888888889 dev: 1.875 relative_accuracy: 0.4014869888475836\n",
      "     27.2 seconds - epoch: 2 loss: 3.4384031295776367 train: 6.09375 dev: 2.875 relative_accuracy: 0.4717948717948718\n",
      "     25.9 seconds - epoch: 3 loss: 3.067910671234131 train: 9.375 dev: 2.75 relative_accuracy: 0.29333333333333333\n",
      "     23.6 seconds - epoch: 4 loss: 3.1321616172790527 train: 6.319444444444445 dev: 2.5 relative_accuracy: 0.3956043956043956\n",
      "     23.7 seconds - epoch: 5 loss: 3.2971112728118896 train: 8.76736111111111 dev: 1.875 relative_accuracy: 0.21386138613861388\n",
      "     24.0 seconds - epoch: 6 loss: 3.2655656337738037 train: 8.958333333333334 dev: 3.0 relative_accuracy: 0.33488372093023255\n",
      "     24.4 seconds - epoch: 7 loss: 3.228858470916748 train: 9.184027777777779 dev: 3.625 relative_accuracy: 0.3947069943289225\n",
      "     24.9 seconds - epoch: 8 loss: 3.178917646408081 train: 9.930555555555555 dev: 3.125 relative_accuracy: 0.3146853146853147\n",
      "     24.5 seconds - epoch: 9 loss: 3.1302778720855713 train: 11.11111111111111 dev: 3.375 relative_accuracy: 0.30375\n",
      "     24.6 seconds - epoch: 10 loss: 3.006812572479248 train: 12.065972222222221 dev: 1.75 relative_accuracy: 0.1450359712230216\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "#model.train()\n",
    "print('max_epochs:', wandb.config.max_epochs)\n",
    "model, losses = train_model(model, train_loader, max_epochs=wandb.config.max_epochs)\n",
    "\n",
    "# save weights\n",
    "cpu_model = model.to(torch.device('cpu'))\n",
    "torch.save(cpu_model, 'resnet-official.pt')\n",
    "if use_cuda:\n",
    "    model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
