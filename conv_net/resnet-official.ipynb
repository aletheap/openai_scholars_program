{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-34 Official\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_dev = \"cuda:0\"\n",
    "device = torch.device(cuda_dev if use_cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "#if use_cuda:\n",
    "#    print('-', torch.cuda.get_device_name(cuda_dev_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/aletheap/official-resnet34\" target=\"_blank\">https://app.wandb.ai/aletheap/official-resnet34</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/aletheap/official-resnet34/runs/a9s35bt1\" target=\"_blank\">https://app.wandb.ai/aletheap/official-resnet34/runs/a9s35bt1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/aletheap/official-resnet34/runs/a9s35bt1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "            'load_workers': 20, \n",
    "            'batch_size': 200,\n",
    "            'max_epochs': 40,\n",
    "         }\n",
    "wandb.init(project=\"official-resnet34\", config=config)\n",
    "\n",
    "#wandb.init(config=args)\n",
    "#wandb.config.initial_lr = 0.1\n",
    "#wandb.config.load_workers = 20\n",
    "#wandb.config.batch_size = 500\n",
    "#wandb.config.max_epochs = 500\n",
    "#wandb.config.training_loops = 1\n",
    "#wandb.config.dropout=.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data. \n",
    "\n",
    "I'm using advice from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/ about regularizing image data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set: 5760 \n",
      "dev_set: 800 \n",
      "test_set: 800 \n",
      "labels: 38\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256),        \n",
    "                                transforms.CenterCrop(224),    \n",
    "                                transforms.ToTensor(),         \n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],    \n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "\n",
    "\n",
    "datadir = \"/home/apower/data/oxford-iiit-pet\"\n",
    "traindir = os.path.join(datadir, 'train')\n",
    "devdir = os.path.join(datadir, 'dev')\n",
    "testdir = os.path.join(datadir, 'test')\n",
    "\n",
    "X_train = torchvision.datasets.ImageFolder(traindir, transform)\n",
    "X_dev = torchvision.datasets.ImageFolder(devdir, transform)\n",
    "X_test = torchvision.datasets.ImageFolder(testdir, transform)\n",
    "\n",
    "num_labels = len(X_train.classes)\n",
    "\n",
    "print('training_set:', len(X_train), '\\ndev_set:', len(X_dev), '\\ntest_set:', len(X_test), '\\nlabels:', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pic = torchvision.transforms.ToPILImage()\n",
    "#to_pic(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train, batch_size=wandb.config.batch_size, shuffle=True, num_workers=wandb.config.load_workers)\n",
    "dev_loader = DataLoader(X_dev, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basing this on the resnet diagram from: https://cv-tricks.com/keras/understand-implement-resnets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet34(pretrained=False, progress=True)\n",
    "#wandb.watch(model)\n",
    "#model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "if use_cuda:\n",
    "    model = model.to(device)\n",
    "\n",
    "# Magic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader, name):\n",
    "    #model = model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    #print('Accuracy of the network on the %s images: %.1f %%' % (name, accuracy))\n",
    "    #wandb.log({name + '_set_accuracy': accuracy})\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, learning_rate=0.1, losses=[10**10], max_epochs=20):\n",
    "    model = model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    wandb.config.optimizer = \"SGD\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        batch = 0\n",
    "        t0 = time.time()\n",
    "        for local_batch, local_labels in loader:\n",
    "            # Transfer to GPU\n",
    "            X, y = local_batch.to(device), local_labels.to(device)\n",
    "            y_pred = model.forward(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('epoch:', epoch, 'batch:', batch, 'loss:', loss.item())\n",
    "            batch += 1\n",
    "        t1 = time.time()\n",
    "        duration = t1-t0\n",
    "        loss_num = loss.item()\n",
    "        train_accuracy = accuracy(model, train_loader, 'train')\n",
    "        dev_accuracy = accuracy(model, dev_loader, 'dev')\n",
    "        wandb.log({'loss': loss.item(), 'secs_per_epoch': duration, 'train_accuracy': train_accuracy, 'dev_accuracy': dev_accuracy})\n",
    "        print(' ' * 4, '%.1f seconds -' % (duration), 'epoch:', epoch, 'loss:', loss_num, 'train:', train_accuracy, 'dev:', dev_accuracy)\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epochs: 40\n",
      "     17.4 seconds - epoch: 0 loss: 4.304771900177002 train: 4.513888888888889 dev: 4.625\n",
      "     15.9 seconds - epoch: 1 loss: 3.7144951820373535 train: 8.715277777777779 dev: 6.625\n",
      "     15.9 seconds - epoch: 2 loss: 3.3128960132598877 train: 14.930555555555555 dev: 12.5\n",
      "     15.5 seconds - epoch: 3 loss: 3.1625919342041016 train: 15.32986111111111 dev: 11.75\n",
      "     15.4 seconds - epoch: 4 loss: 2.8166074752807617 train: 20.65972222222222 dev: 14.125\n",
      "     15.8 seconds - epoch: 5 loss: 2.6467947959899902 train: 22.569444444444443 dev: 15.125\n",
      "     15.3 seconds - epoch: 6 loss: 2.6628758907318115 train: 26.84027777777778 dev: 20.75\n",
      "     15.3 seconds - epoch: 7 loss: 2.329137086868286 train: 34.40972222222222 dev: 24.375\n",
      "     16.4 seconds - epoch: 8 loss: 2.2875921726226807 train: 33.263888888888886 dev: 21.0\n",
      "     15.7 seconds - epoch: 9 loss: 2.3276803493499756 train: 35.260416666666664 dev: 19.5\n",
      "     15.3 seconds - epoch: 10 loss: 2.1557366847991943 train: 47.72569444444444 dev: 25.5\n",
      "     16.3 seconds - epoch: 11 loss: 1.8617379665374756 train: 44.982638888888886 dev: 24.0\n",
      "     15.9 seconds - epoch: 12 loss: 1.5176576375961304 train: 59.236111111111114 dev: 27.0\n",
      "     15.9 seconds - epoch: 13 loss: 0.9671948552131653 train: 77.13541666666667 dev: 30.0\n",
      "     15.9 seconds - epoch: 14 loss: 1.2846777439117432 train: 73.78472222222223 dev: 25.0\n",
      "     16.0 seconds - epoch: 15 loss: 0.281267911195755 train: 97.01388888888889 dev: 30.5\n",
      "     16.0 seconds - epoch: 16 loss: 0.08988475799560547 train: 99.80902777777777 dev: 32.75\n",
      "     15.9 seconds - epoch: 17 loss: 0.028926659375429153 train: 100.0 dev: 33.5\n",
      "     15.9 seconds - epoch: 18 loss: 0.01665436662733555 train: 100.0 dev: 34.25\n",
      "     15.7 seconds - epoch: 19 loss: 0.01754235103726387 train: 100.0 dev: 33.625\n",
      "     15.7 seconds - epoch: 20 loss: 0.008561372756958008 train: 100.0 dev: 34.875\n",
      "     15.9 seconds - epoch: 21 loss: 0.006765806581825018 train: 100.0 dev: 33.25\n",
      "     15.7 seconds - epoch: 22 loss: 0.010243129916489124 train: 100.0 dev: 33.375\n",
      "     15.5 seconds - epoch: 23 loss: 0.0059400321915745735 train: 100.0 dev: 33.25\n",
      "     15.8 seconds - epoch: 24 loss: 0.005268192384392023 train: 100.0 dev: 33.875\n",
      "     16.2 seconds - epoch: 25 loss: 0.004836165811866522 train: 100.0 dev: 33.0\n",
      "     15.9 seconds - epoch: 26 loss: 0.004253304097801447 train: 100.0 dev: 32.75\n",
      "     16.5 seconds - epoch: 27 loss: 0.0038071870803833008 train: 100.0 dev: 34.25\n",
      "     15.4 seconds - epoch: 28 loss: 0.003067493438720703 train: 100.0 dev: 34.125\n",
      "     15.9 seconds - epoch: 29 loss: 0.00405120849609375 train: 100.0 dev: 33.75\n",
      "     16.0 seconds - epoch: 30 loss: 0.0032507062423974276 train: 100.0 dev: 33.0\n",
      "     16.2 seconds - epoch: 31 loss: 0.0030785799026489258 train: 100.0 dev: 34.125\n",
      "     15.3 seconds - epoch: 32 loss: 0.0024376988876610994 train: 100.0 dev: 33.75\n",
      "     15.9 seconds - epoch: 33 loss: 0.0027726173866540194 train: 100.0 dev: 32.375\n",
      "     15.7 seconds - epoch: 34 loss: 0.0023970126640051603 train: 100.0 dev: 34.625\n",
      "     15.9 seconds - epoch: 35 loss: 0.0026186704635620117 train: 100.0 dev: 33.0\n",
      "     16.1 seconds - epoch: 36 loss: 0.002145803067833185 train: 100.0 dev: 33.25\n",
      "     15.7 seconds - epoch: 37 loss: 0.002036952879279852 train: 100.0 dev: 32.625\n",
      "     15.8 seconds - epoch: 38 loss: 0.0025607466232031584 train: 100.0 dev: 33.25\n",
      "     15.9 seconds - epoch: 39 loss: 0.001700925873592496 train: 100.0 dev: 32.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/apower/anaconda3/envs/sandbox1/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "#model.train()\n",
    "print('max_epochs:', wandb.config.max_epochs)\n",
    "model, losses = train_model(model, train_loader, max_epochs=wandb.config.max_epochs)\n",
    "\n",
    "# save weights\n",
    "cpu_model = model.to(torch.device('cpu'))\n",
    "torch.save(cpu_model, 'resnet-official.pt')\n",
    "if use_cuda:\n",
    "    model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
